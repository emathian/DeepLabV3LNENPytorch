{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_table(\"/home/mathiane/SemanticSegmentation/models/research/deeplab/datasets/TumorDetection/dataset/ImageSets/train.txt\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_picts = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                TNE0002_0_0\n",
       "1              TNE0002_0_512\n",
       "2             TNE0002_0_1024\n",
       "3             TNE0002_0_1536\n",
       "4             TNE0002_0_2048\n",
       "                ...         \n",
       "38599    TNE1438_14334_10752\n",
       "38600    TNE1438_14334_11264\n",
       "38601    TNE1438_14334_11776\n",
       "38602    TNE1438_14334_12288\n",
       "38603    TNE1438_14334_12439\n",
       "Name: 0, Length: 38604, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_picts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /home/mathiane/SemanticSegmentation/models/research/deeplab/datasets/TumorDetection/dataset\t[default: None]\n",
      "             dataset_mode: segmentation                  \n",
      "           deep_sup_scale: 0.4                           \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                   fc_dim: 2048                          \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: segmentation                  \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: TypicalAtypical               \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                   netDec: ppm_deepsup                   \n",
      "                   netEnc: resnet50dilated               \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "                num_class: 3                             \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: any                           \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_dev.py\", line 29, in <module>\n",
      "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
      "  File \"/home/mathiane/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 57, in create_dataset\n",
      "    data_loader = CustomDatasetDataLoader(opt)\n",
      "  File \"/home/mathiane/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 73, in __init__\n",
      "    self.dataset = dataset_class(opt)\n",
      "  File \"/home/mathiane/pytorch-CycleGAN-and-pix2pix/data/segmentation_dataset.py\", line 35, in __init__\n",
      "    self.images_path, self.masks_path = make_dataset_from_img_list(self.path_to_imgs_file_list, opt.dataroot, opt.max_dataset_size) \n",
      "  File \"/home/mathiane/pytorch-CycleGAN-and-pix2pix/data/image_folder.py\", line 48, in make_dataset_from_img_list\n",
      "    if Imgname in os.listdir(path_to_img_folder) and Maskname in os.listdir(path_to_mask_folder):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train_dev.py --dataroot /home/mathiane/SemanticSegmentation/models/research/deeplab/datasets/TumorDetection/datasettiny --dataset_mode segmentation --preprocess any --no_flip   --name TypicalAtypical --model segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pyramid pooling\n",
    "# pyramid pooling, deep supervision\n",
    "def conv3x3_bn_relu(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution + BN + relu\"\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=3,\n",
    "                      stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "class PPMDeepsup(nn.Module):\n",
    "    def __init__(self, num_class=3, fc_dim=2048,\n",
    "                 use_softmax=False, pool_scales=(1, 2, 3, 6)):\n",
    "        super(PPMDeepsup, self).__init__()\n",
    "        self.use_softmax = use_softmax\n",
    "\n",
    "        self.ppm = []\n",
    "        for scale in pool_scales:\n",
    "            self.ppm.append(nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(scale),\n",
    "                nn.Conv2d(fc_dim, 512, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.ppm = nn.ModuleList(self.ppm)\n",
    "        self.cbr_deepsup = conv3x3_bn_relu(fc_dim // 2, fc_dim // 4, 1)\n",
    "\n",
    "        self.conv_last = nn.Sequential(\n",
    "            nn.Conv2d(fc_dim+len(pool_scales)*512, 512,\n",
    "                      kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.Conv2d(512, num_class, kernel_size=1)\n",
    "        )\n",
    "        self.conv_last_deepsup = nn.Conv2d(fc_dim // 4, num_class, 1, 1, 0)\n",
    "        self.dropout_deepsup = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, conv_out, segSize=None):\n",
    "        conv5 = conv_out[-1]\n",
    "\n",
    "        input_size = conv5.size()\n",
    "        ppm_out = [conv5]\n",
    "        for pool_scale in self.ppm:\n",
    "            ppm_out.append(nn.functional.interpolate(\n",
    "                pool_scale(conv5),\n",
    "                (input_size[2], input_size[3]),\n",
    "                mode='bilinear', align_corners=False))\n",
    "        ppm_out = torch.cat(ppm_out, 1)\n",
    "\n",
    "        x = self.conv_last(ppm_out)\n",
    "\n",
    "        if self.use_softmax:  # is True during inference\n",
    "            x = nn.functional.interpolate(\n",
    "                x, size=segSize, mode='bilinear', align_corners=False)\n",
    "            x = nn.functional.softmax(x, dim=1)\n",
    "            return x\n",
    "\n",
    "        # deep sup\n",
    "        conv4 = conv_out[-2]\n",
    "        _ = self.cbr_deepsup(conv4)\n",
    "        _ = self.dropout_deepsup(_)\n",
    "        _ = self.conv_last_deepsup(_)\n",
    "\n",
    "        x = nn.functional.log_softmax(x, dim=1)\n",
    "        _ = nn.functional.log_softmax(_, dim=1)\n",
    "\n",
    "        return (x, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPMDeepsup(\n",
       "  (ppm): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=2)\n",
       "      (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=3)\n",
       "      (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=6)\n",
       "      (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (cbr_deepsup): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Sequential(\n",
       "    (0): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout2d(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (conv_last_deepsup): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dropout_deepsup): Dropout2d(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMDeepsup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# READ A MASK\n",
    "##################################################\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('/home/mathiane/SemanticSegmentation/models/research/deeplab/datasets/TumorDetection/dataset/SegmentationClassRaw/TNE1415_12800_14848.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[100,100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im[:,:, 0] == im[:,:, 1]).sum() == 512 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = Image.open('/home/mathiane/SemanticSegmentation/models/research/deeplab/datasets/TumorDetection/dataset/SegmentationClassRaw/TNE1415_12800_14848.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg.getchannel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
